{
 "metadata": {
  "name": "",
  "signature": "sha256:c96e2ab77d66545b4b353b8609c855ca900918321adac8b75b1a483a8b6caf53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lamprey Transcriptome Analysis: Gene Model Overlap Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```\n",
      "Camille Scott [camille dot scott dot w @gmail.com] [@camille_codon]\n",
      "\n",
      "camillescott.github.io\n",
      "\n",
      "Lab for Genomics, Evolution, and Development\n",
      "Michigan State University\n",
      "```"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "About"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explores consensus between assembled transcripts and existing lamprey gene models, using the `gtf_to_genes` library."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    assembly version: lamp03\n",
      "\n",
      "    assembly program: Trinity\n",
      "    \n",
      "    gtf model versin: 7.0.78, at ftp://ftp.ensembl.org/pub/release-78/gtf/petromyzon_marinus/Petromyzon_marinus.Pmarinus_7.0.78.gtf.gz\n",
      "    \n",
      "There is another script in this directory called `petmar-gtf-overlap.py` which loads the database and does the `apply` function to query overlaps for each hit, as those operations take a very long time (these are a definite target for optimization)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!echo $PWD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/camille/w/2015-petMarSB/notebooks\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. [Libraries](#Libraries) \n",
      "* [Data Loading](#Data-Loading)\n",
      "* [Matplotlib RC Settings](#Matplotlib-RC-Settings)\n",
      "* [Existing Gene Models](#Existing-Gene-Models)\n",
      "     1. [Interval Query Initialization](#Interval-Query-Initialization)\n",
      "     * [Utility Functions](#Utility-Functions)\n",
      "     * [Results](#Results)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from libs import *\n",
      "import common as c"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interactive, RadioButtonsWidget\n",
      "from IPython.display import display\n",
      "from IPython.html import widgets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gffutils\n",
      "import pandas as pd\n",
      "import screed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from peasoup import blast"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyprind"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import intervaltree as itree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "store = pd.HDFStore(c.wdir('{}.store.h5'.format(c.prefix)), complib='zlib', complevel=9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Loading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lamp03_db = screed.ScreedDB(c.wdir(c.resources_df.filename['lamp03']))\n",
      "screed.read_fasta_sequences(c.wdir(c.resources_df.filename['petMar2_cdna']))\n",
      "lamp00_db = screed.ScreedDB(c.wdir(c.resources_df.filename['petMar2_cdna']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "tpm_df = store['tpm_df']\n",
      "support_df = store['support_df']"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#blast_panel = store['blast_panel']\n",
      "#blast_df = store['blast_df']"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pM_df = store['pM_df']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lamp03_pM_df = blast.blast_to_df(c.wdir('{}.fasta.x.{}.db.tsv'.format('lamp03', 'petMar2.fa')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lamp00_pM_df = blast.blast_to_df(c.wdir('{}.fa.x.{}.db.tsv'.format('petMar2.cdna', 'petMar2.fa')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matplotlib RC Settings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from matplotlib import rc_context\n",
      "tall_size = (12,24)\n",
      "norm_size = (18,12)\n",
      "mpl_params = {'figure.autolayout': True,\n",
      "               'axes.titlesize': 24,\n",
      "               'axes.labelsize': 16,\n",
      "               'ytick.labelsize': 14,\n",
      "               'xtick.labelsize': 14\n",
      "               }\n",
      "sns.set(style=\"white\", palette=\"muted\", rc=mpl_params)\n",
      "#sns.set_palette(\"Paired\", desat=.6)\n",
      "b, g, r, p = sns.color_palette(\"muted\", 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%config InlineBackend.close_figures = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Existing Gene Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interval Query Initialization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, load the GTF file into a DataFrame. We define a custom parser for the `attributes` column to split on semicolons and load the data into a dictionary, as these fields are non-uniform within the same file.\n",
      "\n",
      "The GTF/GFF standard is defined here: http://useast.ensembl.org/info/website/upload/gff.html?redirect=no"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: Add this file to resources.json\n",
      "gtf_file = c.wdir('Petromyzon_marinus.Pmarinus_7.0.78.gtf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def attr_col_func(col):\n",
      "    d = {}\n",
      "    for item in col.strip(';').split(';'):\n",
      "        pair = item.strip().split(' ')\n",
      "        #print pair\n",
      "        d[pair[0]] = pair[1].strip('\"')\n",
      "    return d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gtf_df = pd.read_table(gtf_file, delimiter='\\t', skiprows=4, header=False, \n",
      "                       names=['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attributes'],\n",
      "                       converters={'attributes': attr_col_func})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gtf_df.set_index('seqname', inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to overlap analysis with the gene models, we'll create interval trees to query against the gene models. This is a dictionary of interval trees, keyed by genome contig ID.\n",
      "\n",
      "The interval tree implementation is provided by the python `intervaltree` library: https://github.com/chaimleib/intervaltree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interval_db = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n, (key, row) in enumerate(gtf_df.iterrows()):\n",
      "    if key not in interval_db:\n",
      "        interval_db[key] = itree.IntervalTree()\n",
      "    start = row.start\n",
      "    end = row.end\n",
      "    if start == end:\n",
      "        end += 1\n",
      "    interval_db[key][start:end] = n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Utility Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a genome contig and a range, get the appropriate interval tree and find overlapping intervals. Return the DataFrame indices for matching features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_overlap_rows(seqname, start, end, db=interval_db):\n",
      "    try:\n",
      "        tree = db[seqname]\n",
      "    except Exception as e:\n",
      "        #print >>sys.stderr, 'No interval tree for sequence', seqname, e\n",
      "        return []\n",
      "    # Turns out the intervaltree requires (min,max) style coordinates\n",
      "    rows = [item.data for item in tree[min(start,end):max(start,end)]]\n",
      "    return rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_overlaps(df, db=interval_db, block_size=5000):\n",
      "    bar = pyprind.ProgBar(len(df) / block_size, stream=1)\n",
      "    \n",
      "    df['features'] = None\n",
      "    for block_start in range(0,len(df), block_size):\n",
      "        bar.update()\n",
      "        df.ix[block_start:block_start+block_size, 'features'] = \\\n",
      "            df.ix[block_start:block_start+block_size].apply(\n",
      "            lambda row: get_overlap_rows(row.sseqid, row.sstart, row.send, db), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quantify_overlaps(df, gtf_df=gtf_df):\n",
      "    df['tr'] = df.index\n",
      "    df.sort(columns=['tr', 'sseqid'], inplace=True)\n",
      "    \n",
      "    overlapped_rows = set()\n",
      "    df.apply(lambda row: overlapped_rows.update(row.features), axis=1)\n",
      "    print '{:.2f}% of all features overlapped'.format(float(len(overlapped_rows)) / len(gtf_df) * 100)\n",
      "    for feature, perc in (gtf_df.ix[list(overlapped_rows)].groupby(by='feature').count().source / \\\n",
      "        gtf_df.groupby(by='feature', axis=0).count().source * 100).iteritems():\n",
      "        print '{:.2f}% of {:s} features overlapped'.format(perc, feature)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's check lamp00 as a baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_overlaps(lamp00_pM_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0%                          100%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[                              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#                             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 11.883 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##                            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 16.126 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###                           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 14.833 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[####                          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 13.558 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#####                         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 13.084 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[######                        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 12.466 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#######                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 11.920 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[########                      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 11.364 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#########                     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 10.988 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##########                    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 10.383 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###########                   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 9.927 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 9.529 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#############                 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 8.800 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############                ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 8.362 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###############               ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 7.937 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[################              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 7.150 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#################             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 6.758 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##################            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 6.370 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###################           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 5.547 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[####################          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 5.159 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#####################         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 4.735 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[######################        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 3.947 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#######################       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 3.548 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[########################      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 3.140 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#########################     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 2.363 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##########################    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 1.966 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###########################   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 1.577 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############################  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.791 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############################# ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.396 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total time elapsed: 15.807 sec\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quantify_overlaps(lamp00_pM_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "89.93% of all features overlapped\n",
        "91.98% of CDS features overlapped"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "96.27% of UTR features overlapped\n",
        "89.69% of exon features overlapped\n",
        "79.88% of gene features overlapped\n",
        "95.00% of start_codon features overlapped\n",
        "98.04% of stop_codon features overlapped\n",
        "81.35% of transcript features overlapped\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks alright; now for our assembly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_overlaps(lamp03_pM_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0%                          100%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[                              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#                             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 350.688 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##                            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 332.511 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###                           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 316.097 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[####                          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 302.061 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#####                         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 290.559 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[######                        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 279.644 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#######                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 269.406 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[########                      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 259.947 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#########                     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 249.895 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##########                    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 241.019 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###########                   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 229.919 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 218.959 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#############                 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 207.883 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############                ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 196.814 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###############               ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 185.345 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[################              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 174.640 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#################             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 163.346 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##################            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 151.614 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###################           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 140.085 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[####################          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 128.836 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#####################         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 116.720 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[######################        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 104.401 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#######################       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 91.657 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[########################      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 79.132 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[#########################     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 66.116 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##########################    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 53.399 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[###########################   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 40.068 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############################  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 26.987 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[############################# ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 13.309 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total time elapsed: 408.056 sec\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quantify_overlaps(lamp03_pM_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "90.02% of all features overlapped\n",
        "89.60% of CDS features overlapped"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "95.83% of UTR features overlapped\n",
        "89.39% of exon features overlapped\n",
        "93.53% of gene features overlapped\n",
        "85.12% of start_codon features overlapped\n",
        "91.10% of stop_codon features overlapped\n",
        "93.94% of transcript features overlapped\n"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO\n",
      "1. Normalize vs. amount of genome covered by features\n",
      "2. Use lamp00 as control for this method \n",
      "3. Pull out overlapped for more comparison\n",
      "4. Do again with only transcripts mapping to genome + other and do same process\n",
      "5. Graph align old dna, new dna; transcripts\n",
      "6. CEGMA "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}